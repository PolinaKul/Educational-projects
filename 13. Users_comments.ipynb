{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfc91c2",
   "metadata": {},
   "source": [
    "Имеются комментарии пользователей, предоставленные сервисом \"Викишоп\". Необходимо обучить модель различать позитивные и негативные комментарии. качество работы модели будет проверяться метрикой F1. для решения поставленной задачи выполним следующие шаги:\n",
    "\n",
    "1. Подготовка данных. Загрузим и подготовим предоставленные данные.\n",
    "2. Обучим несколько моделей.\n",
    "3. Выводы. Подведем итоги полученных результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e28d45",
   "metadata": {},
   "source": [
    "**1  Подготовка**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b17a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6217a164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc1ca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb335bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd4f9ec",
   "metadata": {},
   "source": [
    "Проведем обработку данных - лемматизируем текст, удалим лишние символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdc682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "lemm_text = []\n",
    "for sen in range(0, len(data['text'])):\n",
    "    document = re.sub(r'\\W', ' ', str(data.text[sen]))     \n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    document = document.lower()\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    lemm_text.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text'] = lemm_text\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c678163",
   "metadata": {},
   "source": [
    "Разделим выборку. Размер тестовой выборки - 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train['lemm_text']\n",
    "target_train = train['toxic']\n",
    "features_test = test['lemm_text']\n",
    "target_test = test['toxic']\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca93d4",
   "metadata": {},
   "source": [
    "**2  Обучение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model', LogisticRegression())])\n",
    "model_lr.fit(features_train, target_train)\n",
    "predictions_1 = model_lr.predict(features_train)\n",
    "result_1 = f1_score(target_train, predictions_1)\n",
    "print(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    " ('model', RandomForestClassifier())])\n",
    "rf_params = {\n",
    " 'tfidf__max_features':[2000],\n",
    " 'tfidf__ngram_range': [(1, 2)],\n",
    " 'tfidf__stop_words': ['english'],\n",
    " 'model__max_depth': [1, 10]\n",
    "}\n",
    "model_rf = GridSearchCV(pipe_rf, param_grid=rf_params, cv = 5)\n",
    "model_rf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334494bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = model_rf.predict(features_train)\n",
    "result_2 = f1_score(target_train, predictions_2)\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd50811",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt = Pipeline([('tfidf', TfidfVectorizer()),\n",
    " ('model', DecisionTreeClassifier())])\n",
    "dt_params = {\n",
    " 'tfidf__max_features':[2000],\n",
    " 'tfidf__ngram_range': [(1, 2)],\n",
    " 'tfidf__stop_words': ['english'],\n",
    " 'model__max_depth': [1, 10]\n",
    "}\n",
    "model_dt = GridSearchCV(pipe_dt, param_grid=dt_params, cv = 5)\n",
    "model_dt.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cdc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_3 = model_dt.predict(features_train)\n",
    "result_3 = f1_score(target_train, predictions_3)\n",
    "print(result_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12447be",
   "metadata": {},
   "source": [
    "Среди трех обученных моделей наилучший результат по метрике F1 у модели LogisticRegression.\n",
    "Проверяем результаты на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e32011",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_4 = model_lr.predict(features_test)\n",
    "result_4 = f1_score(target_test, predictions_4)\n",
    "print(result_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec7315",
   "metadata": {},
   "source": [
    "**3  Выводы**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6a59b",
   "metadata": {},
   "source": [
    "**Заключение**\n",
    "\n",
    "От интернет-магазина \"Викишоп\" были предоставлены данные с комментариями и правками в описаниях товаров, сделанными пользователями магазина. К комментариям были проставлены оценки - позитивные или негативные.\n",
    "\n",
    "Текст был обработан: были исключены лишние символы, все буквы приведены к строчному написанию, удалены стоп-слова. Текст был переведен в векторное представление.\n",
    "\n",
    "Были обучены модели LogisticRegression, DeсisionTreeClassifier, Randomforest. На обучающей выборке наилучший результат по метрике F1 получился у модели LogisticRegression - 0.77. Работа модели проверена на тестовой выборке. Результат также не меньше 0,75 - 0,75083.\n",
    "\n",
    "Для решения поставленной заказчиком задачи рекомендована к использованию модель LogisticRegression."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1466,
    "start_time": "2023-01-29T13:50:15.403Z"
   },
   {
    "duration": 2244,
    "start_time": "2023-01-29T13:50:18.739Z"
   },
   {
    "duration": 33,
    "start_time": "2023-01-29T13:50:23.483Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-29T13:50:25.568Z"
   },
   {
    "duration": 42114,
    "start_time": "2023-01-29T13:50:27.886Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
